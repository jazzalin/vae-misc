{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import re\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "from torchvision.datasets import MNIST\n",
    "from skimage import io, transform\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from seglearn.transform import InterpLongToWide, SegmentX, FeatureRep, PadTrunc\n",
    "from seglearn.pipe import Pype\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "#         self.fc1 = nn.Linear(hidden_dim, 100)\n",
    "#         self.fc2 = nn.Linear(100, output_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "#         out = F.relu(self.fc1(out))\n",
    "#         out = F.softmax(self.fc2(out[:, -1, :]), dim=1)\n",
    "        out = self.fc2(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADING\n",
    "class ExerciseDataset(Dataset):\n",
    "    \"\"\"Shoulder exercise dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, npy_file, length=None, transform=None, sanity_check=None):\n",
    "        self.dataset = np.load(npy_file, allow_pickle=True).item()\n",
    "        self.seq_length = length\n",
    "        self.data = self.process_dataset(length)\n",
    "        self.original_data = self.data.copy()\n",
    "        self.data = self.data.astype(np.float)\n",
    "        self.targets = self.dataset['exnum']\n",
    "        self.original_targets = self.targets.copy()\n",
    "#         self.subject = self.dataset['subject']\n",
    "#         self.original_subject = self.subject.copy()\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        if sanity_check is not None:\n",
    "            self.data = [self.data[sanity_check]]\n",
    "            self.targets = [self.targets[sanity_check]]\n",
    "\n",
    "        assert (len(self.data) == len(self.targets))\n",
    "        \n",
    "    def process_dataset(self, length):\n",
    "        shape = [data.shape[0] for data in self.dataset['X']]\n",
    "        if length is None:\n",
    "            average_len = round(sum(shape) / len(shape))\n",
    "            self.seq_length = average_len\n",
    "        processed, _, _ = PadTrunc(width=self.seq_length).transform(X=self.dataset['X'])\n",
    "        return processed\n",
    "    \n",
    "    def fold(self, fold_indices):\n",
    "        # Create fold for K-fold validation\n",
    "        self.data = self.original_data[fold_indices]\n",
    "        self.targets = self.original_targets[fold_indices]\n",
    "        self.subject = self.original_subject[fold_indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return torch.from_numpy(self.data[idx][:, 1:]), self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = {\n",
    "    0: 'PEN',\n",
    "    1: 'FLEX',\n",
    "    2: 'SCAP',\n",
    "    3: 'ABD',\n",
    "    4: 'IR',\n",
    "    5: 'ER',\n",
    "    6: 'DIAG',\n",
    "    7: 'ROW',\n",
    "    8: 'SLR'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "input_dim = 3\n",
    "hidden_dim = 128\n",
    "layer_dim = 3\n",
    "output_dim = 9 # 9 classes\n",
    "# seq_dim = dataset.seq_length\n",
    "\n",
    "# iterations_per_epoch = len(train_loader)\n",
    "best_acc = 0\n",
    "patience, trials = 100, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ExerciseDataset(\"resampled_nar.npy\")\n",
    "# dataset = ExerciseDataset(\"recon_synthetic_acc_nar.npy\")\n",
    "# dataset = ExerciseDataset(\"recon_vrae.npy\")\n",
    "# dataset = ExerciseDataset(\"recon_acc.npy\", length=200)\n",
    "# recon_dataset = ExerciseDataset(\"recons.npy\", length=200)\n",
    "# new_dataset = ExerciseDataset(\"generated.npy\", length=200)\n",
    "dataset = ExerciseDataset(\"cropped_resampled_acc_nar.npy\", length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "assert train_size + test_size == len(dataset)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6522"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(dataset, batch_size=4, num_workers=6, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset = new_dataset\n",
    "# index = np.random.randint(50)\n",
    "# plt.rcParams.update({'font.size': 22})\n",
    "# plt.figure(figsize=(24, 12))\n",
    "# label = dataset[index][1][0]\n",
    "# print(\"Label: {}\".format(dataset[index][1]))\n",
    "# plt.plot(dataset[index][0][:, 0], label=\"x\")\n",
    "# plt.plot(dataset[index][0][:, 1], label=\"y\")\n",
    "# plt.plot(dataset[index][0][:, 2], label=\"z\")\n",
    "\n",
    "\n",
    "# plt.plot(dataset.dataset['original'][index][:, 0], label=\"recon_x\")\n",
    "# plt.plot(dataset.dataset['original'][index][:, 1], label=\"recon_y\")\n",
    "# plt.plot(dataset.dataset['original'][index][:, 2], label=\"recon_z\")\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.title(\"Sequence reconstruction example (exercise: {})\".format(exercises[label]))\n",
    "# plt.xlabel(\"Time [s]\")\n",
    "# plt.ylabel(r'acceleration $[ms^{-2}]$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original = dataset.dataset['original']\n",
    "# original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(3, 128, num_layers=3, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim, 0.5)\n",
    "# clf.load_state_dict(torch.load(\"best_200_92.pth\"))\n",
    "# clf.load_state_dict(torch.load(\"clf_pre_aug.pth\"))\n",
    "clf.load_state_dict(torch.load(\"clf_post_aug.pth\"))\n",
    "clf = clf.cuda()\n",
    "clf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracY: 0.7795154860472248\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "predicted = []\n",
    "actual = []\n",
    "total = 0\n",
    "correct = 0\n",
    "for j, val in enumerate(test_loader):\n",
    "    x_val, y_val = val\n",
    "    actual.append(y_val.numpy())\n",
    "    \n",
    "    x_val = x_val.float().cuda()\n",
    "    y_val = y_val.float().cuda()\n",
    "\n",
    "    out = clf(x_val)\n",
    "    preds = F.softmax(out, dim=1).argmax(dim=1)\n",
    "    predicted.append(preds.cpu().numpy())\n",
    "    \n",
    "    total += y_val.size(0)\n",
    "    correct += (preds == y_val).sum().item()\n",
    "acc = correct / total\n",
    "print(\"Overall accuracY: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.95"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(acc * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = [label for array in actual for label in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = [label for array in predicted for label in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PEN','FLEX', 'SCAP', 'ABD', 'IR', 'ER', 'DIAG', 'ROW', 'SLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.05, 'Post-augmentation accuracy: 77.95')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1728x1728 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(24, 24))\n",
    "conf_matrix = confusion_matrix(ac, pre)\n",
    "plt.matshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"Post-augmentation accuracy: {}\".format(round(acc*100, 2)))\n",
    "# print(classification_report(ac, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pl' from 'sklearn.metrics' (/home/lja/Documents/waterloo/4A/CS/assignments/lib/python3.7/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5f38889fb820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pl' from 'sklearn.metrics' (/home/lja/Documents/waterloo/4A/CS/assignments/lib/python3.7/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}